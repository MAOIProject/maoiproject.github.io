<!DOCTYPE html>
<html class="no-js">
  <head>

    <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<title>MAOI Project</title>
<meta name="description" content="">
<meta name="viewport" content="width=device-width, initial-scale=1">
<!-- Place favicon.ico and apple-touch-icon.png in the root directory -->

<!-- CSS -->
<link rel="stylesheet" href="/css/owl.carousel.css" />
<link rel="stylesheet" href="/css/bootstrap.min.css" />
<link rel="stylesheet" href="/css/font-awesome.min.css" />
<link rel="stylesheet" href="/css/airspace.css" />
<link rel="stylesheet" href="/css/style.css" />
<link rel="stylesheet" href="/css/ionicons.min.css" />
<link rel="stylesheet" href="/css/animate.css" />
<link rel="stylesheet" href="/css/responsive.css" />
<link rel="stylesheet" href="/css/syntax.css" />

<!-- Js -->
<script src="//ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script>
<script>window.jQuery || document.write('<script src="js/vendor/jquery-1.10.2.min.js"><\/script>')</script>
<script src="/js/bootstrap.min.js"></script>
<script src="/js/owl.carousel.min.js"></script>
<script src="/js/plugins.js"></script>
<script src="/js/min/waypoints.min.js"></script>
<script src="/js/jquery.counterup.js"></script>


<script src="/js/main.js"></script>

<link rel="shortcut icon" type="image/png" href="img/pepperFavico.png">
<!--
/*
 * Airspace
 * Ported to Jekyll by Andrew Lee
 * https://github.com/ndrewtl/airspace-jekyll
 * Designed and Developed by ThemeFisher
 * https://themefisher.com/
 *
 */
-->


  </head>
  <body>


    <!-- Header Start -->
<header>
<div class="container">
  <div class="row">
    <div class="col-md-12">
      <!-- header Nav Start -->
      <nav class="navbar navbar-default">
        <div class="container-fluid">
          <!-- Brand and toggle get grouped for better mobile display -->
          <div class="col-md-4">
            <h1 class="site-title"><a href="/" rel="home">MAOI Project</a></h1>
            <h2 class="site-description">Multimodal Analysis of Opinions in Interactions</h2>
          </div>
          <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            </button>
            <!-- <a class="navbar-brand" href="index.html">
              <img src="/img/pepperLogo.png" alt="Logo">
            </a> -->
          </div>
            <!-- Collect the nav links, forms, and other content for toggling -->
            <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
              <ul class="nav navbar-nav navbar-right">
                <li><a href="/">Home</a></li>
                <!-- <li><a href="/work">Work</a></li> -->
                <!-- <li><a href="/blog">Blog</a></li> -->
                <li><a href="/publications">Publications</a></li>
                <li><a href="/contact">Contact</a></li>
                <!-- <li><a href="/resources">Resources</a></li> -->
              </ul>
            </div><!-- /.navbar-collapse -->
          </div><!-- /.container-fluid -->
        </nav>
      </div>
    </div>
  </div>
</header><!-- header close -->



    <section id="description-slider">
  <div class="container">
    <div class="row">
      <div class="col-md-10 col-md-offset-2">
        <div class="block">
          <h1 class="animated fadeInUp"><br> Human-Agent Multimodal Interactions </h1>
          <!-- <p class="animated fadeInUp">Some blabla can be put here</p> -->
        </div>
      </div>
    </div>
  </div>
</section>

<section id="description">
    <div class="container">
      <div class="row">
        <div class="col-md-10 col-md-offset-2">
          <div class="block">
            <p class="animated fadeInUp">
              The MOAI project tackles multimodal opinion analysis methods in human-agent multimodal interactions in order to extract information concerning user preferences. Such information is dedicated to enrich user profiles for companion robots and virtual assistants. This challenging issue has been so far rarely and partially handled by the state of the art. The proposed approach relies on Conditional Random Fields (CRF) that have been chosen for their flexibility in order to take advantage of both the generalization capability of machine learning methods and the fine-grain modeling of semantic rules. As recordings of face-to face human-agent interactions are not yet massively available, such flexible methods constitute an alternative to deep learning methods. In this promising context, the MAOI project targets two major breakthroughs: i) feature learning driven by a priori knowledge and psycho-linguistic models in order to learn users’ preferences and ii) the integration of various levels of analysis (lexical, syntactic, prosodic, dialogic) through latent variables inside hidden CRF, allowing for grounding the opinion detection in the context of human-agent interaction.
            </p>
          </div>
        </div>
      </div>
    </div>
</section>


<section id="work-packages">
  <div class="container">
    <div class="row">
        <div class="col-md-10 col-md-offset-2">
          <div class="block">
            <!-- <h1></h1>
            <p>
              The research plan will be organized in 6 Workpackages. WP0 is dedicated to the Management. WP1-4 are four Workpackages corresponding to the different phases of the PhD’s work that will be carried out under our supervision, with the collaboration of current PhD students and with scientific exchanges with the researchers of Telecom-ParisTech associated with the research topic Social Computing lead by Chloé Clavel. WP1-4 address all together the scientific breakthroughs presented in Section 1.3. We have tried to make each WP able to bring solutions to specific methodological issues. However, the WPs are not entirely independent as the answers brought in one WP should benefit to other WPs. First, we will work on the annotation schema in order to annotate opinions in interactions (WP1). Second, we will work on the modeling of the verbal content of opinion in interactions within the CRF models and word embedding approaches (WP2). Then, we will focus on the integration of acoustic features in the model (WP3). Finally, WP4 is dedicated to the evaluation of the methods on different corpora. There will also be a WP5 dedicated to dissemination. Table 2 and Figure 1 present the effort distribution per WP and participant and the Gantt of the project, respectively.
            </p> -->

            MAOI is organized with <b>4 work packages:</b>
            <ul>
                <li><b>WP1 – Annotation of opinions in interactions</b></li>
                <!-- : aims at providing a structured annotation of the opinions contained in the different corpora of interactions</li> -->
                <li><b>WP2 – From linguistic rules to feature functions</b></li>
                <!-- : aims at providing a methodology for the integration of complex and inter- actional linguistic features in CRF-based models for the detection of opinions in interactions.</li> -->
                <li><b>WP3 – Acoustic modeling of opinions in interactions</b></li>
                <!-- : aims at providing a methodology for the integration of acoustic features in multimodal CRF-based models for the detection of opinions in interactions.</li> -->
                <li><b>WP4 – Evaluation in interaction context</b></li>
                <!-- : aims at providing a methodology for the evaluation of opinion detection systems that are grounded in a human-agent interaction.</li> -->
                <!-- <li><b>WP5 – Dissemination</b>: A public web site will be set up at the beginning of the project for the purpose of dissemination and promotion of the project results. The site will describe the MAOI project and facilitate the retrieval of public documents and publications.</li> -->
            </ul>
          </div>
        </div>
    </div>
  </div>
</section>

<!-- <section id="Impact and benefits of the project">
    <div class="container">
        <div class="row">
            <div class="col-md-10 col-md-offset-2">
                <div class="block">
                    <div class="section-title">
                        <h3>
                            Socio-Economic and industrial impact
                        </h3>
                    </div>
                </div>
            </div>
        </div>

        <div class="row">
            <div class="col-md-10 col-md-offset-2">
                <div class="block">
                    <div class="section-title">
                        <h3>
                            Scientific impact
                        </h3>
                    </div>
                </div>
            </div>
        </div>
    </div>
</section> -->


<!-- <section id="wp0">
  <div class="container">
    <div class="row">
      <div class="col-md-10 col-md-offset-2">
        <div class="block">
        <h1>WP0 – Project Management</h1>
        <p>
          The research plan will be organized in 6 Workpackages. WP0 is dedicated to the Management. WP1-4 are four Workpackages corresponding to the different phases of the PhD’s work that will be carried out under our supervision, with the collaboration of current PhD students and with scientific exchanges with the researchers of Telecom-ParisTech associated with the research topic Social Computing lead by Chloé Clavel. WP1-4 address all together the scientific breakthroughs presented in Section 1.3. We have tried to make each WP able to bring solutions to specific methodological issues. However, the WPs are not entirely independent as the answers brought in one WP should benefit to other WPs. First, we will work on the annotation schema in order to annotate opinions in interactions (WP1). Second, we will work on the modeling of the verbal content of opinion in interactions within the CRF models and word embedding approaches (WP2). Then, we will focus on the integration of acoustic features in the model (WP3). Finally, WP4 is dedicated to the evaluation of the methods on different corpora. There will also be a WP5 dedicated to dissemination. Table 2 and Figure 1 present the effort distribution per WP and participant and the Gantt of the project, respectively.
        </p>
      </div>
      </div>
    </div>
  </div>
</section>

<section id="wp1">
  <div class="container">
    <div class="row">
      <div class="col-md-10 col-md-offset-2">
        <div class="block">
        <h1>WP1 – Annotation of opinions in interactions</h1>
        <p><b>Objective: </b> WP1 aims at providing a structured annotation of the opinions contained in the different corpora of interactions</p>
        <p><b>Approach:</b> According to the model of the users’ likes and dislikes defined in [6], we will define an annotation scheme allowing to annotate opinions in interactions using different existing English corpora : 1) the SEMAINE corpus [9] consisting of audio-visual recordings of face- to-face interactions between users and embodied conversational agents 2) the NOXI corpus developed in the context of European project Aria-valuspa6 3) the human-agent negociation corpus developed at the Institute of Creative Technologies consisting of audiovisual recordings of human-human and human-agent interactions performing a negociation task [3]. The scheme will allow us to annotate the opinion structure (source, opinion’s expression and targets) and the interaction context (for example, the topic structure of the conversation or the agent’s communcative goals). The annotation will be carried using crowdsourcing platforms such as Crowdflower https://www.crowdflower.com/ by at least three different labelers. The annotation agreement score will be computed in order to evaluate the annotation consistency and reliability.
        </p>
        <p><b>Expected results:</b> annotated corpora that will feed the training of the system developed in WP2 and WP3, on the one hand and the reference corpus for the evaluation in WP4, on the other hand.
        </p>
        <p><b>Success indicators:</b> high agreement scores of the annotations</p>
      </div>
      </div>
    </div>
  </div>
</section>

<section id="wp2">
  <div class="container">
    <div class="row">
      <div class="col-md-10 col-md-offset-2">
        <div class="block">
        <h1>WP2 – From linguistic rules to feature functions</h1>
        <p><b>Objective: </b>WP2 aims at providing a methodology for the integration of complex and inter- actional linguistic features in CRF-based models for the detection of opinions in interactions.</p>
        <p><b>Approach: </b>We will use the linguistic rules that we have implemented using grammars in [6] in order to define feature functions that will be used as an input of CRF models. The first version of the opinion analysis systems will focus on the lexical, syntactic and dialogic-based feature functions. The lexical level models will rely on both sentiment lexicons such as Wordnet Affect and word embeddings features. We will investigate the potential of CRF for a classification using transcripts from oral speech. The discriminative nature of CRF will enable some strong linguistic rules combined with word embedding features to emerge directly from the learning phase. In particular, the feature functions will model : i) the relations between the evaluative expressions, on the one hand, and their target and their source, on the other hand; ii) the conversation context (dialogic level). We will evaluate the differences of behavior of our model running on manual transcripts vs. automatic speech transcripts.</p>
        <p><b>Expected results: </b>First version of the text-based opinion detection system.</p>
        <p><b>Success indicators: </b>F-score for the performance of the system. As it will be the first machine learning system dealing with opinion detection in interactions, it will be difficult to compare ourselves to other system performance. However, the F-score will be compared with a baseline system (for example using LogReg), with the rule-based method evaluated in [6] and with other deep learning approaches such as Long Short Term Memory (LSTM) networks.</p>
        <<p><b>Tasks and corresponding deliverables: </b></p>
      </div>
      </div>
    </div>
  </div>
</section>

<section id="wp3">
  <div class="container">
    <div class="row">
      <div class="col-md-10 col-md-offset-2">
        <div class="block">
        <h1>WP2 – From linguistic rules to feature functions</h1>
        <p><b>Objective: </b>WP3 aims at providing a methodology for the integration of acoustic features in multimodal CRF-based models for the detection of opinions in interactions.</p>
        <p><b>Approach: </b>Acoustic features dedicated to model opinions will be integrated to the model developed in WP2. We will use existing speech feature extraction tools (such as OpenSmile or Covarep) in order to extract prosodic (pitch, intensity and speech rate) and voice quality features, as well as classical audio features (Mel Frequency Cepstral Coefficients) and advanced temporal integration/pooling approaches based on different signal segmentation (for example pause segmentation). We will investigate a latent state model in order to model the opinion of a speaker using a variant of CRF called Hidden Conditional Random Fields (HCRF). We will work on finer grain prosodic patterns relying on a speech to text alignment such as done in [2] to integrate in the CRF and HCRF feature functions. Besides, we will envisage learning audio representations using recurrent neural networks trained on larger audio dataset with emotion labels.</p>
        <p><b>Expected results: </b>First version of the multimodal opinion detection system.</p>
        <p><b>Success indicators: </b>F-score for the performance of the system. As it will be the first system dealing with multimodal opinion detection in interactions, it will be difficult to compare ourselves from other system performance. However, the F-score will be compared with a baseline system (for example using LogReg) and with other deep learning approaches such as Long Short Term Memory (LSTM) networks. We will also evaluate the multimodal contribution by comparing to the F-score obtained using audio only and with the text-based system developed in WP2.</p>
        <<p><b>Tasks and corresponding deliverables: </b>T3.1 : Multimodal opinion detection system in interactions (v1 system) from T0+18 to T0+30</p>
      </div>
      </div>
    </div>
  </div>
</section>

<section id="wp4">
  <div class="container">
    <div class="row">
      <div class="col-md-10 col-md-offset-2">
        <div class="block">
        <h1>WP2 – From linguistic rules to feature functions</h1>
        <p><b>Objective: </b>WP4 aims at providing a methodology for the evaluation of opinion detection systems that are grounded in a human-agent interaction.</p>
        <p><b>Approach: </b>Each version of the system will be evaluated on the three different corpora. We will evaluate the performance of the system for the detection of the users’ likes and dislikes and their target. We will also evaluate the contribution of the interaction context modeling in the performance of the system by evaluating two versions of the system : the first one using features relying on the single user’s utterances and the second one using features relying on the dialogue history.</p>
        <p><b>Expected results: </b>Evaluation methodology and in-depth analysis of the detection system results.</p>
        <p><b>Success indicators: </b>Ability of the result analysis to provide research leads for system improvement.</p>
        <<p><b>Tasks and corresponding deliverables: </b></p>
      </div>
      </div>
    </div>
  </div>
</section>

<section id="wp5">
  <div class="container">
    <div class="row">
      <div class="col-md-10 col-md-offset-2">
        <div class="block">
        <h1>WP2 – From linguistic rules to feature functions</h1>
        <p><b>Objective: </b> </p>
        <p><b>Approach: </b> </p>
        <p><b>Expected results: </b> </p>
        <p><b>Success indicators: </b></p>
        <<p><b>Tasks and corresponding deliverables: </b></p>
      </div>
      </div>
    </div>
  </div>
</section>  -->











    <!-- footer Start -->
<footer>
  <div class="container">
    <div class="row">
      <div class="col-md-12">
        <div class="footer-manu">
          <ul>
            <li><a href="#">About Us</a></li>
            <li><a href="/contact">Contact us</a></li>
            <!-- <li><a href="#">How it works</a></li> -->
            <li><a href="/blog">Blog</a></li>
            <!-- <li><a href="#">Terms</a></li> -->
          </ul>
        </div>
        <p>Copyright &copy; Design &amp; Developed by <a href="http://www.themefisher.com">Themefisher</a>. All rights reserved.</p>
      </div>
    </div>
  </div>
</footer>


    </body>
</html>
